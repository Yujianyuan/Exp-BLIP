# Official PyTorch Implementation of Exp-BLIP (BMVC 2023 Oral).

![Exp-BLIP training Framework](figs/overview.pdf)


> [**Describe Your Facial Expressions by Linking Image Encoders and Large Language Models**]<br>
> [Yujian Yuan](https://vipl.ict.ac.cn/edu/student/master/202210/t20221019_123529.html), [Jiabei Zeng](https://vipl.ict.ac.cn/edu/teacher/mastersupvisor/202205/t20220517_35778.html), [Shiguang Shan](https://scholar.google.com/citations?user=Vkzd7MIAAAAJ&hl=zh-CN)<br>Institute of Computing Technology, Chinese Academy of Sciences;
 University of Chinese Academy of Sciences



## ðŸ“° News

**[2022.9.15]** VideoMAE is decided by **BMVC 2023** as a **Oral** presentation! ðŸŽ‰ <br>
**[2022.8.25]** Exp-BLIP is accepted by **BMVC 2023** ! ðŸŽ‰ <br>
**[2023.8.20]** Code and trained models will be released here. Welcome to **watch** this repository for the latest updates.
