# Official PyTorch Implementation of Exp-BLIP (BMVC 2023 Oral).

![Exp-BLIP training Framework](figs/overview.jpg)


> [**Describe Your Facial Expressions by Linking Image Encoders and Large Language Models**]<br>
> [Yujian Yuan](https://vipl.ict.ac.cn/edu/student/master/202210/t20221019_123529.html), [Jiabei Zeng](https://vipl.ict.ac.cn/edu/teacher/mastersupvisor/202205/t20220517_35778.html), [Shiguang Shan](https://scholar.google.com/citations?user=Vkzd7MIAAAAJ&hl=zh-CN)<br>Institute of Computing Technology, Chinese Academy of Sciences;
 University of Chinese Academy of Sciences



## üì∞ News

**[2023.9.12]** Exp-BLIP is decided by **BMVC 2023** as a **Oral** presentation! üéâ <br>
**[2023.8.25]** Exp-BLIP is accepted by **BMVC 2023** ! üéâ <br>
**[2023.8.20]** Code and trained models will be released here. Welcome to **watch** this repository for the latest updates.


<a name="download"></a>
## ‚û°Ô∏è Captions and Models Download

<a name="text"></a>
### (1) Sythesized captions
| Captions type                         |                                                    Link                                                    |
|:------------------------------------|:-------------------------------------------------------------------------------------------------------:| 
| AU captions    					   |     [Google Drive](https://drive.google.com/drive/folders/13I0nCB0t5-FcKnQ48xOPVno_Eerb83Uj?usp=sharing)|
| Emotion captions                    |     [Google Drive]    |
| Facial expression captions          |     [Google Drive]    | 
